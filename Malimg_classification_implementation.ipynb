{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "Malimg classification implementation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6dtjnL1c9w1"
      },
      "source": [
        "#Importing necessary packages\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import models\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Activation ,Flatten, Conv2D, Input\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RD_UPuRdo9l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "049b6b71-d9c7-4153-ee22-88c46815ee94"
      },
      "source": [
        "#Importing google drive since colab disk does not have required space to load the datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp_rdQ32QmG5"
      },
      "source": [
        "# **Malimg Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiP8YZ5nNprs"
      },
      "source": [
        "Due to colab limits, images were resized to 112x112"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqEv-URyjybV",
        "outputId": "eada542c-1c60-4bfb-bedf-7a862e87ea25"
      },
      "source": [
        "#generating our dataset\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "batches = ImageDataGenerator().flow_from_directory(directory='/content/drive/MyDrive/malimg_paper_dataset_imgs',target_size=(112,112), batch_size=10000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9339 images belonging to 25 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR1vYppHkpJw"
      },
      "source": [
        "#Generating images with labels\n",
        "imgs, labels = next(batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s525v7WzkyHK",
        "outputId": "c815e80f-711d-497f-b348-3d93aa814e18"
      },
      "source": [
        "#Seeing shape of images and labels\n",
        "imgs.shape, labels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9339, 112, 112, 3), (9339, 25))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdFTXzhUZasa",
        "outputId": "0a2e52eb-6ef2-4977-9e19-daea1093a1b5"
      },
      "source": [
        "%cd /content/drive/MyDrive/malimg_paper_dataset_imgs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/malimg_paper_dataset_imgs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mejQllAkZjiS"
      },
      "source": [
        "#Saving the np array for future use\n",
        "np.save(\"imgs\",imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3ZW3OiMaKIa"
      },
      "source": [
        "#Saving np array for future use\n",
        "np.save(\"labels\",labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBl1nO0lJ4s9"
      },
      "source": [
        "#Code for loading saved variables\n",
        "#imgs=np.load('/content/drive/MyDrive/Malimg/malimg_paper_dataset_imgs/imgs.npy')\n",
        "#labels=np.load('/content/drive/MyDrive/Malimg/malimg_paper_dataset_imgs/labels.npy')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTOm1pX2qZKd",
        "outputId": "b1f7fb98-3cd5-416b-c4cf-422bddfa349d"
      },
      "source": [
        "#Generating train and test data\n",
        "#from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(imgs/255.,labels, test_size=0.1)\n",
        "X_train.shape, X_test.shape , y_train.shape, y_test.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8405, 112, 112, 3), (934, 112, 112, 3), (8405, 25), (934, 25))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr7u7miqsIpQ",
        "outputId": "66b34ed6-01fc-4f54-dd7e-2e5e7728642b"
      },
      "source": [
        "model_vgg16_conv = VGG16(weights='imagenet', include_top=False) #taking vgg-16 model and removing last 3 fc and softmax layers\n",
        " \n",
        "#Creating our own input format\n",
        "keras_input = Input(shape=(112,112,3), name = 'image_input') \n",
        "    \n",
        "#Use the generated model \n",
        "output_vgg16_conv = model_vgg16_conv(keras_input)\n",
        "    \n",
        "#Add the fully-connected layers \n",
        "x = Flatten(name='flatten')(output_vgg16_conv)\n",
        "x = Dense(4096, activation='relu', name='fc1')(x)\n",
        "x = Dense(4096, activation='relu', name='fc2')(x)\n",
        "x = Dense(25, activation='softmax', name='predictions')(x)\n",
        "    \n",
        "#final model creation \n",
        "pretrained_model = Model(inputs=keras_input, outputs=x)\n",
        "pretrained_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "image_input (InputLayer)     [(None, 112, 112, 3)]     0         \n",
            "_________________________________________________________________\n",
            "vgg16 (Functional)           (None, None, None, 512)   14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              18878464  \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 25)                102425    \n",
            "=================================================================\n",
            "Total params: 50,476,889\n",
            "Trainable params: 50,476,889\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt9eyGC-t9XQ"
      },
      "source": [
        "#defining learning rate scheduler as learning rate is reduced by factor of 10 after 20th epoch\n",
        "def scheduler(epoch, lr):\n",
        "  if epoch == 21:\n",
        "    return lr/10\n",
        "  else:\n",
        "    return lr"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bcy7OEWCwKdI"
      },
      "source": [
        "#adding regularization to pretrained vgg-16 convolutional layers\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "def add_regularization(model, regularizer=tf.keras.regularizers.l2(0.0005)):\n",
        "\n",
        "    #error checking if regularizer object is not passed\n",
        "    if not isinstance(regularizer, tf.keras.regularizers.Regularizer): \n",
        "      print(\"Regularizer must be a subclass of tf.keras.regularizers.Regularizer\")\n",
        "      return model\n",
        "    #if layer has a regularizer attribute set it to required value\n",
        "    for layer in model.layers:\n",
        "        for attr in ['kernel_regularizer']:\n",
        "            if hasattr(layer, attr):\n",
        "              setattr(layer, attr, regularizer)\n",
        "\n",
        "    # When we change the layers attributes, the change only happens in the model config file\n",
        "    #Therefore to achieve the desired effect we need to save and reload the model\n",
        "    model_json = model.to_json()\n",
        "\n",
        "    #The problem with this is that the weights get lost when saving and reloading.\n",
        "    # Save the weights before reloading the model.\n",
        "    tmp_weights_path = os.path.join(tempfile.gettempdir(), 'tmp_weights.h5')\n",
        "    model.save_weights(tmp_weights_path)\n",
        "\n",
        "    # load the model from the config\n",
        "    model = tf.keras.models.model_from_json(model_json)\n",
        "    \n",
        "    # Reload the model weights\n",
        "    model.load_weights(tmp_weights_path, by_name=True)\n",
        "    return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0poL5lC_wOwe"
      },
      "source": [
        "#Adding regularization\n",
        "pretrined_model=add_regularization(pretrained_model)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZr1o4g0w3FW"
      },
      "source": [
        "#Setting learning rate and momentum\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=0.001,momentum=0.9)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyabw9s-xCEH"
      },
      "source": [
        "#Compiling the model\n",
        "pretrined_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JR347aEc9w-"
      },
      "source": [
        "#Training the model. All the variables are initialized as described in research paper\n",
        "batch_size = 6\n",
        "epochs  = 25\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "history = pretrined_model.fit(X_train, y_train,\n",
        "                    epochs=epochs, callbacks=[callback], batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v8Esa4zF19X"
      },
      "source": [
        "Colab got stuck when ran the code second time for saving the model so trained the model on different colab ID and now loading it here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wY-uSiijID-8"
      },
      "source": [
        "pretrined_model=models.load_model('/content/drive/MyDrive/Malimg/')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ei2SZlrc9w_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74062267-e753-48df-ad24-088c2fad3da5"
      },
      "source": [
        "#Testing on test set\n",
        "print(\"starting evaluating\")\n",
        "pretrined_model.evaluate(X_test, y_test, verbose=0)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "starting evaluating\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.8986002206802368, 0.9957173466682434]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLGeiXoSQubH"
      },
      "source": [
        "# **Microsoft Malware Classification Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "jQwphOhIc9w_",
        "outputId": "2c6939d0-2c7c-416a-bc02-dbede282c3d2"
      },
      "source": [
        "#Reading the train labels file\n",
        "import pandas as pd\n",
        "df=pd.read_csv('/content/drive/MyDrive/malware-classification/trainLabels.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>01kcPWA9K2BOxQeS5Rju</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>04EjIdbPV5e1XroFOpiN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>05EeG39MTRrI6VY21DPd</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>05rJTUWYAKNegBk2wE8X</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0AnoOZDNbPXIr2MRBSCJ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Id  Class\n",
              "0  01kcPWA9K2BOxQeS5Rju      1\n",
              "1  04EjIdbPV5e1XroFOpiN      1\n",
              "2  05EeG39MTRrI6VY21DPd      1\n",
              "3  05rJTUWYAKNegBk2wE8X      1\n",
              "4  0AnoOZDNbPXIr2MRBSCJ      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxt5826NazVu",
        "outputId": "87c585f9-a467-422c-b1cb-0685f1f44d92"
      },
      "source": [
        "#Seeing number of training instances\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10868, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa7ZX9_7n-9B",
        "outputId": "39912743-e2c4-4c86-8818-d9552f7d6db1"
      },
      "source": [
        "#Changing directory to Microsoft Malware Dataset\n",
        "%cd /content/drive/MyDrive/malware-classification/train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/malware-classification/train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wbW7SS_bTQv",
        "outputId": "f0de2717-185e-4865-a240-2c8403b126e7"
      },
      "source": [
        "#Changing dataframe to numpy array so that we can utilize the labels name and \n",
        "# save the images in label folders after creating them as we can see in the \n",
        "#next step\n",
        "records = df.to_records(index=False)\n",
        "print(records.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10868,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaXbf6SrSz_l"
      },
      "source": [
        "## Process of creating images from .bytes file is as follows\n",
        "\n",
        "\n",
        "1.   Trainlabels file contains name of every train file along with its label.\n",
        "2.   We take a record from trainlabels and add .bytes so that it matches name of the file and then we open that file.\n",
        "3.   After opening a file, we already know that every line of .bytes file contains some line offset at the start followed by 16 hexadecimal representation form of malware code. A number of these lines make complete malware code.\n",
        "4.   We ignore the first offset part and convert hexadecimal representation to decimal representation and store all the decimal numbers in an array.\n",
        "5.   Then we calculate file size as width of image depends on file size.\n",
        "6.   Then we create a matrix with specified width and height as total decimal numbers divided by width.\n",
        "7.   At last we convert the matrix to an image format and save it.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCHTHv2jbM5F",
        "outputId": "f96936cf-f680-463d-a9de-a095af45f5db"
      },
      "source": [
        "#importing os for calculating file size as we have to keep width of the image according to the\n",
        "#file size\n",
        "import os \n",
        "#directory where we have to keep malware images\n",
        "dir='/content/drive/MyDrive/malware-classification/train/train_imgs/'\n",
        "#Taking each tuple(name,label) from records\n",
        "for t in records:                                                    \n",
        "    FileToOpen=t[0]\n",
        "    #Adding .bytes so that it matches name of the file      \n",
        "    FileToOpen+='.bytes'\n",
        "    #Opening .bytes file                                                   \n",
        "    with open(FileToOpen) as f:\n",
        "      #Declaring array which will store decimal values of 8 bits in a contiguous manner                                            \n",
        "      array=[]\n",
        "      #Taking each line in .bytes file                                                              \n",
        "      for line in f:\n",
        "        #Splitting it into offset part + 16 hexadecimal numbers                                                       \n",
        "        xx=line.split() \n",
        "        #Checking for some errors if line is not of above format                                                   \n",
        "        if len(xx)!=17:                                                    \n",
        "          continue\n",
        "        #xx[1:] contains only hexadecimal numbers, there were some ?? which \n",
        "        #were replaced by zeroes otherwise store corresponding decimal representation  \n",
        "        array.append([int(i,16) if i!='??' else 0 for i in xx[1:] ])       \n",
        "      #Converting it to a numpy array so that we can reshape it                                                                     \n",
        "      array=np.array(array)\n",
        "      #For calculating file size                                                \n",
        "      f.seek(0, os.SEEK_END)\n",
        "      #Converting file size to kilobytes                                               \n",
        "      kbyt=f.tell()/1024\n",
        "      #Code for initializing width of image based on file size                                                   \n",
        "      if kbyt < 10:\n",
        "        width=32\n",
        "      elif kbyt < 30:\n",
        "        width=64\n",
        "      elif kbyt < 60:\n",
        "        width=128\n",
        "      elif kbyt < 100:\n",
        "        width=256\n",
        "      elif kbyt < 200:\n",
        "        width=384\n",
        "      elif kbyt < 500:\n",
        "        width=512\n",
        "      elif kbyt < 1000:\n",
        "        width=768\n",
        "      else:\n",
        "        width=1024\n",
        "      #Calculating height of image(total decimal numbers/width)  \n",
        "      height=int((array.shape[0]*16)/width)\n",
        "      #Creating matrix by taking only width*height numbers of decimal numbers\n",
        "      #rest of the numbers are not taken as almost complete malware code is included\n",
        "      #in this fashion and we reject few numbers at the end otherwise it will not form an\n",
        "      #image and then we would have to pad it which would alter malware code\n",
        "      Matrix=array[:width*height//16,:]\n",
        "      #Reshaping it to (height x width)\n",
        "      decMat = np.reshape(Matrix,(height,width))\n",
        "      #Generating image from matrix\n",
        "      im = Image.fromarray(np.uint8(decMat))\n",
        "      #Saving the image in corresponding labels folder\n",
        "      im.save(dir+str(t[1])+'/'+t[0]+'.png', \"PNG\")\n",
        "#Prints end of pre-processing\n",
        "print(\"Preprocessing is  done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing is  done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXdDVrm1bB52"
      },
      "source": [
        "## Model Creation and Training Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiNg8tsm4mk0",
        "outputId": "f5657301-a824-4836-97fa-9bcab1077210"
      },
      "source": [
        "#Generating dataset\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "batches = ImageDataGenerator().flow_from_directory(directory='/content/drive/MyDrive/malware-classification/train/train_imgs',target_size=(112,112), batch_size=11000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10868 images belonging to 9 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iZ9nlp65YjX"
      },
      "source": [
        "#Generating images with labels\n",
        "imgs, labels = next(batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfoJ49JVNH1L",
        "outputId": "36d88d7d-c454-41f9-a29b-ccc5d42fb907"
      },
      "source": [
        "#Visualizing shape of images and labels\n",
        "imgs.shape, labels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10868, 112, 112, 3), (10868, 9))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnbsdOSnN8ky"
      },
      "source": [
        "#Code for loading saved variables\n",
        "#imgs=np.load('/content/drive/MyDrive/malware-classification/imgsmicro.npy')\n",
        "#labels=np.load('/content/drive/MyDrive/malware-classification/labelsmicro.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Em7TKQTilaOF",
        "outputId": "13840223-a743-4643-d76e-805b3f1d63ac"
      },
      "source": [
        "#Splitting into train and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(imgs/255.,labels, test_size=0.1)\n",
        "X_train.shape, X_test.shape , y_train.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9781, 112, 112, 3), (1087, 112, 112, 3), (9781, 9), (1087, 9))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZbDCPQilict",
        "outputId": "5fb9e097-0901-4988-c185-bf21aad08b6f"
      },
      "source": [
        "#Imporing vgg model and removing last 3 fc and softmax layers\n",
        "model_vgg16_conv2 = VGG16(weights='imagenet', include_top=False)\n",
        "model_vgg16_conv2.summary()\n",
        "    \n",
        "#Creating our own input format\n",
        "keras_input2 = Input(shape=(112,112,3), name = 'image_input2')\n",
        "    \n",
        "#Using the generated model \n",
        "output_vgg16_conv2 = model_vgg16_conv2(keras_input2)\n",
        "    \n",
        "#Add the fully-connected layers \n",
        "x2 = Flatten(name='flatten2')(output_vgg16_conv2)\n",
        "x2 = Dense(4096, activation='relu', name='fc12')(x2)\n",
        "x2 = Dense(4096, activation='relu', name='fc22')(x2)\n",
        "x2 = Dense(9, activation='softmax', name='predictions2')(x2)\n",
        "    \n",
        "#Final model creation \n",
        "pretrained_model2 = Model(inputs=keras_input2, outputs=x2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYf5Hf_DmhBy"
      },
      "source": [
        "#Adding regularization\n",
        "pretrined_model2=add_regularization(pretrained_model2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6cIF9MHmu97"
      },
      "source": [
        "#Compiling our model\n",
        "pretrined_model2.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKa4q-9Woahy",
        "outputId": "1801b47f-940e-4544-ceca-14ed7feb7d19"
      },
      "source": [
        "#Training of our model\n",
        "batch_size = 8\n",
        "epochs  = 25\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "history2 = pretrined_model2.fit(X_train, y_train,\n",
        "                    epochs=epochs, callbacks=[callback], batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1223/1223 [==============================] - 112s 64ms/step - loss: 4.7566 - accuracy: 0.8271\n",
            "Epoch 2/25\n",
            "1223/1223 [==============================] - 77s 63ms/step - loss: 4.2549 - accuracy: 0.9530\n",
            "Epoch 3/25\n",
            "1223/1223 [==============================] - 77s 63ms/step - loss: 4.1173 - accuracy: 0.9675\n",
            "Epoch 4/25\n",
            "1223/1223 [==============================] - 77s 63ms/step - loss: 3.9808 - accuracy: 0.9777\n",
            "Epoch 5/25\n",
            "1223/1223 [==============================] - 77s 63ms/step - loss: 3.8733 - accuracy: 0.9803\n",
            "Epoch 6/25\n",
            "1223/1223 [==============================] - 77s 63ms/step - loss: 3.7659 - accuracy: 0.9850\n",
            "Epoch 7/25\n",
            "1223/1223 [==============================] - 77s 63ms/step - loss: 3.6742 - accuracy: 0.9868\n",
            "Epoch 8/25\n",
            "1223/1223 [==============================] - 77s 63ms/step - loss: 3.5687 - accuracy: 0.9935\n",
            "Epoch 9/25\n",
            "1223/1223 [==============================] - 78s 63ms/step - loss: 3.4842 - accuracy: 0.9924\n",
            "Epoch 10/25\n",
            "1223/1223 [==============================] - 77s 63ms/step - loss: 3.4099 - accuracy: 0.9890\n",
            "Epoch 11/25\n",
            "1223/1223 [==============================] - 77s 63ms/step - loss: 3.3057 - accuracy: 0.9965\n",
            "Epoch 12/25\n",
            "1223/1223 [==============================] - 77s 63ms/step - loss: 3.2328 - accuracy: 0.9948\n",
            "Epoch 13/25\n",
            "1223/1223 [==============================] - 77s 63ms/step - loss: 3.1467 - accuracy: 0.9969\n",
            "Epoch 14/25\n",
            "1223/1223 [==============================] - 77s 63ms/step - loss: 3.0706 - accuracy: 0.9971\n",
            "Epoch 15/25\n",
            "1223/1223 [==============================] - 77s 63ms/step - loss: 3.0075 - accuracy: 0.9940\n",
            "Epoch 16/25\n",
            "1223/1223 [==============================] - 77s 63ms/step - loss: 2.9373 - accuracy: 0.9932\n",
            "Epoch 17/25\n",
            "1223/1223 [==============================] - 77s 63ms/step - loss: 2.8697 - accuracy: 0.9929\n",
            "Epoch 18/25\n",
            "1223/1223 [==============================] - 77s 63ms/step - loss: 2.7812 - accuracy: 0.9985\n",
            "Epoch 19/25\n",
            "1223/1223 [==============================] - 77s 63ms/step - loss: 2.7125 - accuracy: 0.9993\n",
            "Epoch 20/25\n",
            "1223/1223 [==============================] - 77s 63ms/step - loss: 2.6458 - accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "1223/1223 [==============================] - 77s 63ms/step - loss: 2.5820 - accuracy: 0.9999\n",
            "Epoch 22/25\n",
            "1223/1223 [==============================] - 77s 63ms/step - loss: 2.5328 - accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "1223/1223 [==============================] - 77s 63ms/step - loss: 2.5266 - accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "1223/1223 [==============================] - 77s 63ms/step - loss: 2.5204 - accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "1223/1223 [==============================] - 77s 63ms/step - loss: 2.5142 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yalXteqq5QMl",
        "outputId": "bf61c28f-da5a-48aa-82aa-bd5a990c4e36"
      },
      "source": [
        "#Evaluating our model on test set\n",
        "pretrined_model2.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34/34 [==============================] - 5s 85ms/step - loss: 2.6064 - accuracy: 0.9816\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.606424331665039, 0.9816007614135742]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9i5q23HG5aol",
        "outputId": "f08ae854-44c7-48ab-e7f1-4b75575bc3bb"
      },
      "source": [
        "#Saving our model for future use\n",
        "pretrined_model2.save('saved_model/my_model') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}